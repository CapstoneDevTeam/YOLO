from ultralytics import YOLO
import cv2
import numpy as np
import mediapipe as mp
import csv

# YOLO Î™®Îç∏ Î°úÎìú
model = YOLO("weights/best.pt")

# MediaPipe Ï¥àÍ∏∞Ìôî
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# ÏòÅÏÉÅ Ïó¥Í∏∞
video_path = "videos/0505_orange.mov.mp4"
cap = cv2.VideoCapture(video_path)
fps = cap.get(cv2.CAP_PROP_FPS)
print(fps)
skip_frames = 0

# cv2.VideoCapture.readÌï®ÏàòÎäî ÌäúÌîå ÌòïÌÉúÎ°ú Í∞íÏùÑ Î∞òÌôò
# retÎäî Ture / Flase
# first_frameÏùÄ Ï≤´ ÌîÑÎ†àÏûÑ. ÎßåÏïΩ readÎ•º ÌïúÎ≤à Îçî ÌïúÎã§Î©¥ Í∑∏ Îã§Ïùå ÌîÑÎ†àÏûÑÏùÑ Í∞ÄÏ†∏Ïò¥
# Ïù¥Îïå Ïù¥ÎØ∏ÏßÄÎ•º Í∞ÄÏ†∏Ïò¨ Îïå Numpy Î∞∞Ïó¥ ÌòïÌÉúÎ°ú Í∞ÄÏ†∏Ïò¥
ret, first_frame = cap.read()
if not ret:
    print("‚ùå Ï≤´ ÌîÑÎ†àÏûÑÏùÑ ÏùΩÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
    cap.release()
    exit()

# dictionary Íµ¨Ï°∞. keyÏôÄ value Íµ¨Ï°∞.
# valueÍ∞íÏùÑ YOLO class Ïù¥Î¶ÑÍ≥º ÎßûÏ∂§Ï∂§
all_colors = {
    'red': 'Hold_Red',
    'orange': 'Hold_Orange',
    'yellow': 'Hold_Yellow',
    'green': 'Hold_Green',
    'blue': 'Hold_Blue',
    'purple': 'Hold_Purple',
    'pink': 'Hold_Pink',
    'white': 'Hold_White',
    'black': 'Hold_Black',
    'gray': 'Hold_Gray',
    'lime': 'Hold_Lime',
    'sky': 'Hold_Sky',
}
#joinÏùÑ ÌÜµÌï¥ Î¨∏ÏûêÏó¥ Ï´ô Î≥¥Ïó¨Ï§å.
print("üé® ÏÑ†ÌÉù Í∞ÄÎä•Ìïú ÏÉâÏÉÅ: " + ", ".join(all_colors.keys()))
#stripÏùÄ Í≥µÎ∞± Ï†úÍ±∞, lowerÏùÄ Îã§ ÏÜåÎ¨∏ÏûêÎ°ú Î≥ÄÌôò
selected_color = input("‚úÖ ÏõêÌïòÎäî ÌôÄÎìú ÏÉâÏÉÅ ÏûÖÎ†•: ").strip().lower()

if selected_color not in all_colors:
    print("‚ùå Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ ÏÉâÏÉÅÏûÖÎãàÎã§. Ï¢ÖÎ£åÌï©ÎãàÎã§.")
    exit()

selected_class = all_colors[selected_color]
print(f"üéØ ÏÑ†ÌÉùÎêú ÌÅ¥ÎûòÏä§: {selected_class}")

#ÌôîÎ©¥ ÌöåÏ†Ñ ÏóÜÏñ¥ÎèÑ ÎêòÎäîÍ≤å ÏûàÏùå
first_frame = cv2.rotate(first_frame, cv2.ROTATE_90_CLOCKWISE)
#openCVÍ∞Ä BGRÏùÑ Ïç®ÏÑú Í∑∏ÎÉ• BGRÏùÑ Ïù¥Ïö©Ìï¥Î≤ÑÎ¶¨Ïûê Ìï¥ÏÑú rgbÎ°ú Î∞îÍæ∏ÏßÄ ÏïäÏïòÏùå.
#first_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)
# modelÏùÄ YOLOÏßÄ. Í∑ºÎç∞ YOLOÍ∞Ä Í∞íÏùÑ Î∞òÌôòÌï† Îïå Î¶¨Ïä§Ìä∏Î°ú Î∞òÌôòÌï®. Í∑∏ Ï≤´Î≤àÏß∏ Î¶¨Ïä§Ìä∏Ïùò Ï†ïÎ≥¥Î•º Î∞õÍ∏∞ ÏúÑÌï¥[0]ÏùÑ Î∂ôÏûÑ.
result = model(first_frame)[0]

if result.masks is None:
    print("‚ùå ÎßàÏä§ÌÅ¨ ÏóÜÏùå (YOLO Í≤∞Í≥º)")
    cap.release()
    exit()

#BGRÍ∏∞Ï§ÄÏúºÎ°ú ÏûëÏÑ±Ìï®.
color_map = {
    'Hold_Red':     (0, 0, 255),       # üî¥
    'Hold_Orange':  (0, 165, 255),     # üü†
    'Hold_Yellow':  (0, 255, 255),     # üü°
    'Hold_Green':   (0, 255, 0),       # üü¢
    'Hold_Blue':    (255, 0, 0),       # üîµ
    'Hold_Purple':  (204, 50, 153),    # üü£
    'Hold_Pink':    (203, 192, 255),   # üíó
    'Hold_Lime':    (50, 255, 128),    # Ïó∞Îëê
    'Hold_Sky':     (255, 255, 0),     # ÌïòÎäòÏÉâ
    'Hold_White':   (255, 255, 255),   # ‚ö™
    'Hold_Black':   (30, 30, 30),      # ‚ö´
    'Hold_Gray':    (150, 150, 150),   # ÌöåÏÉâ
}

# YOLO ÎßàÏä§ÌÅ¨ ‚Üí contour Ï∂îÏ∂ú
# masks.dataÎ•º Ìï¥Ïïº ÌîΩÏÖÄÏùò 3Ï∞®Ïõê Î∞∞Ïó¥ ÎÇòÏò¥
# YOLOÍ∞Ä Í∞êÏßÄÌïú Í∞ùÏ≤¥ Ïàò, ÎßàÏä§ÌÅ¨ Ïù¥ÎØ∏ÏßÄÏùò ÎÜíÏù¥, ÎßàÏä§ÌÅ¨ Ïù¥ÎØ∏ÏßÄÏùò ÎÑìÏù¥Í∞Ä Îã¥Í≤®ÏûàÏùå.
# Í∑∏ÎûòÏÑú masksÏùò 3Ï∞®Ïõê Î∞∞Ïó¥ÏùÑ Ï∂úÎ†•Ìï¥Î≥∏Îã§Î©¥ 0~1Ïùò Í∞íÏù¥ Îã¥Í≤®ÏûàÎäîÎç∞ Í∑∏Í≤å Í∞ùÏ≤¥Ïùº ÌôïÎ•†Ïù∏ÎìØ
masks = result.masks.data
# Ïù¥Í±¥ Î∞îÏö¥Îî©Î∞ïÏä§ Ï†úÍ≥µÏù∏Îç∞ ÌïÑÏöî ÏóÜÍ∏¥ Ìï¥
boxes = result.boxes
# model.namesÎäî YOLOÍ∞Ä Ïù∏ÏãùÌï† Ïàò ÏûàÎèÑÎ°ù ÌïôÏäµÎêú ÌÅ¥ÎûòÏä§ ID ‚Üî ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ Îß§Ìïë ÎîïÏÖîÎÑàÎ¶¨
# Ïôú ÌïÑÏöîÌïòÎÉêÎ©¥ YOLOÎäî classÏù¥Î¶ÑÏóêÎäî Í¥ÄÏã¨Ïù¥ ÏóÜÍ≥† class IDÎßå Î¥Ñ. Í∑∏ÎûòÏÑú Ïö∞Î¶¨Í∞Ä ÏïåÏïÑÎ≥º Ïàò ÏûàÍ≤å class Ïù¥Î¶ÑÏúºÎ°ú ÍµêÏ≤¥.
names = model.names
# [:2]Îäî Ï≤òÏùåÎ∂ÄÌÑ∞ 2Î≤àÏß∏ÍπåÏßÄ Í∞íÎßå Ïì∞Ïûê.Í∑∏Í≤å Ïù¥ÎØ∏ÏßÄÏùò ÎÜíÏù¥ÏôÄ ÎÑìÏù¥ÏûÑ.
img_h, img_w = first_frame.shape[:2]
# Îπà Î¶¨Ïä§Ìä∏ ÏÑ†Ïñ∏, Ïú§Í≥ΩÏÑ†Ïóê ÎåÄÌïú Ï†ïÎ≥¥ Îã¥ÏùÑÍ±∞ÏûÑ.
hold_contours = []

# masks.shape[0]ÏùÄ Í∞ùÏ≤¥ Í≤ÄÏ∂úÌïú Ïàò, Ï¶â ÌôÄÎìú Ïàò ÎßåÌÅº Î∞òÎ≥µÌï®
for i in range(masks.shape[0]):
    # GPUÏóê ÌÖêÏÑú ÏûàÏúºÎãàÍπå CPUÏóê ÏòÆÍ∏¥Îã§ÎäîÎç∞ Ïù¥Í±∞ Ïûò Î™®Î•¥Í≤†Ïùå.
    # YOLOÍ∞Ä PyTorchÏù¥Í≥† PyTorchÎäî GPUÏóêÏÑú Í≥ÑÏÇ∞Îêú ÌÖêÏÑú Ïù¥Ïö©.
    # Í∑ºÎç∞ numpy / opencvÎäî GPUÏôÄ Ìò∏Ìôò X.
    mask = masks[i].cpu().numpy()
    # YOLO Î™®Îç∏ÏóêÏÑú maskÎ•º Ìï† Îïå ÌÅ¨Í∏∞Î•º Î∞îÍøîÏÑú ÌïòÍ∏∞ ÎïåÎ¨∏Ïóê(ÏïÑÎßà ÌïôÏäµÏãúÌÇ® ÌÅ¨Í∏∞) Îã§Ïãú ÏõêÎûòÏùò Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î°ú ÎêòÎèåÎ†§Ïïº Ìï®.
    # Í∑ºÎç∞ Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î•º ÎßàÏùåÎåÄÎ°ú Î∞îÍæºÎã§? Ï°∞Í∏àÏùò ÏàòÏ†ïÏù¥ ÌïÑÏöîÌïòÍ≤†ÏßÄ. Í∑∏ÎûòÏÑú cv2.INTER_NEARESTÎ•º Ïù¥Ïö©
    # Ïù¥Í±¥ Í∞ÄÍπåÏö¥ ÌîΩÏÖÄÏùÑ Í∑∏Ï†Ä Î≥µÏÇ¨ÌïòÎäî Í±∞ÏûÑ. ÏòÅÏÉÅÏ≤òÎ¶¨ ÏàòÏóÖ Îïå Î∞∞Ïö¥ Ïù¥ÎØ∏ÏßÄ resized Î∞©Ïãù Í∑∏Í±∞.
    resized_mask = cv2.resize(mask, (img_w, img_h), interpolation=cv2.INTER_NEAREST)
    # ÌôïÎ•†Ïù¥ 0.5Ïù¥ÏÉÅÏù∏ Í≤ÉÎßå. 255 Í≥±Ìï¥ÏÑú 0~1ÏùÑ 0~255Î°ú Î∞îÍøîÏ§å. openCVÏóêÏÑúÎäî 0~255Î•º ÏÇ¨Ïö©ÌïòÎØÄÎ°ú.
    binary_mask = (resized_mask > 0.7).astype(np.uint8) * 255
    # findContoursÎäî Ïú§Í≥ΩÏÑ†ÏùÑ Ï∞æÏïÑÏ§å. Í∑∏ ÌîΩÏÖÄÏù¥ 0Ïù¥ÎÉê ÏïÑÎãàÎÉêÎ•º Î≥¥Í≥† ÌåêÎã®Ìï®. 0Ïù¥ ÏïÑÎãàÎùºÎ©¥ Í∞ùÏ≤¥Í≤†ÏßÄ.
    # RETR_EXTERNALÏùÑ ÏÇ¨Ïö©Ìï¥ÏÑú Ïô∏Í≥ΩÎßå Ï∞æÏùå
    # CHAIN_APPROX_SIMPLEÏùÑ ÌïÑÏöîÌïú Í≤ÉÎßå ÎïÄ. ÏßÅÏÑ†ÏúºÎ°ú Ï≠â ÏûàÏúºÎ©¥ Î™®Îì† Ï†êÏóê ÎåÄÌïú Ï†ïÎ≥¥ ÌïÑÏöî ÏóÜÍ≥† ÎÅùÍ≥º ÎÅù Ï†êÎßå Îî∞Î©¥ Îê®.
    # Îí§Ïóê  _Îäî Í≥ÑÏ∏µ Íµ¨Ï°∞ Îã¥Í≥†ÏûàÎäîÍ±¥Îç∞ ÌïÑÏöî ÏóÜÏñ¥ÏÑú _Î°ú ÏîÄ.
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # class_idÎ•º Í∞ÄÏ†∏Ïò®Îã§. Î≠ê Î≥¥ÌÜµ tensor(3.)Ïù¥Î†áÍ≤å ÏûàÏúºÎãà item()ÏúºÎ°ú 3.0Îßå ÎΩëÍ≥† intÎ°ú 3ÏúºÎ°ú ÎßåÎì§Ïñ¥Ï§å
    # .item()ÏùÄ PyTorch ÌÖêÏÑúÏóêÏÑú Í∞íÎßå Ï∂îÏ∂úÌïòÎäî Ìï®Ïàò
    cls_id = int(boxes.cls[i].item())
    # Í∞ùÏ≤¥Ïóê ÎåÄÌïú Ïã†Î¢∞ÎèÑ
    conf = float(boxes.conf[i].item())
    # ÏïÑÍπå Ïù¥Î¶Ñ ÏÑ§Ï†ïÌïúÍ±∞ Îß§ÌïëÍ≥ºÏ†ïÏù¥ÏßÄ Î≠ê.
    class_name = names[cls_id]
    # .getÏùÄ ÎîïÏÖîÎÑàÎ¶¨ ÏûêÎ£åÌòïÏóêÏÑú Ïì∞Îäî Ìï®Ïàò. keyÍ∞í Î≥¥Í≥† valueÍ∞í Î∞òÌôòÌï¥Ï£ºÎäîÍ±∞ÏßÄ. Îí§ÏóêÎäî ÏóÜÏùÑ Í≤ΩÏö∞ ÎîîÌè¥Ìä∏Í∞í. ÌïòÏñÄÏÉâÏúºÎ°ú ÏÑ§Ï†ïÌï®.
    color = color_map.get(class_name, (255, 255, 255))

    # ÏûÖÎ†•Ìïú ÏÉâÏóê ÎåÄÌïúÍ≤ÉÎßå Í∑∏Î¶¨Í≥† Ïú§Í≥ΩÏÑ†Ïù∏Í≤ÉÎßå
    if class_name == selected_class and contours:

        #ÌôÄÎìúÏùò Ï§ëÏã¨Í∞í Ï¢åÌëú Ï∂îÏ∂ú
        # Í∞ùÏ≤¥ ÌïòÎÇòÏî© Î≥¥ÎãàÍπå [0]ÏúºÎ°ú ÌïúÍ∞úÏùò Í∞ùÏ≤¥Îßå Î¥ÑÎ¥Ñ
        contour = contours[0]
        # momentsÎäî Ïú§Í≥ΩÏÑ† Î∞õÏïÑÏÑú Î©¥Ï†Å, Ï§ëÏã¨Ï¢åÌëú Í≥ÑÏÇ∞Ïóê ÌïÑÏöîÌïú Í∞íÎì§ÏùÑ Îã¥ÏùÄ ÎîïÏÖîÎÑàÎ¶¨ Î∞òÌôò
        M = cv2.moments(contour)
        #m00ÏùÄ Î©¥Ï†Å, m10ÏùÄ xÏ¢åÌëú Ï¥ùÌï©, m01ÏùÄ yÏ¢åÌëú Ï¥ùÌï©
        # Ï¶â Î¨¥Í≤åÏ§ëÏã¨ Íµ¨ÌïòÎäîÍ±∞ÏßÄÏßÄ
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
        else:
            cx, cy = 0, 0
        
        # appendÎäî Î¶¨Ïä§Ìä∏Ïóê Í∞í ÌïòÎÇò Ï∂îÍ∞ÄÌïòÎäî Ìï®Ïàò
        # ÏßÄÍ∏àÍπåÏßÄ ÏñªÏùÄ Ï†ïÎ≥¥ ÎÑ£Ïñ¥Ï£ºÎäîÍ±∞ÏßÄ.
        hold_contours.append({
            "class_name": class_name,
            "contour": contours[0],
            "color": color,
            "label": f"{class_name} {conf:.2f}",
            "center": (cx, cy)
        })


# CSV ÌååÏùº Ï§ÄÎπÑ
csv_file = open('data/hand_foot_coordinates.csv', 'w', newline='')
csv_writer = csv.writer(csv_file)
csv_writer.writerow([
    'frame_idx',
    'left_hand_x', 'left_hand_y',
    'right_hand_x', 'right_hand_y',
])

# ÌîÑÎ†àÏûÑ Ïù∏Îç±Ïä§
frame_idx = 0
# Ï∂úÎ†• ÏòÅÏÉÅ ÎßåÎì§Î†§Í≥† ÏÑ§Ï†ïÏ†ï
out = None

grip_records = []  # [part, hold_id, cx, cy]
# Ïù¥ÎØ∏ Ïû°ÏùÄ ÌôÄÎìúÏù∏ÏßÄ ÌåêÎã®, Ï§ëÎ≥µ Î∞©ÏßÄÏö©.
already_grabbed = {}

# Pose Ï∂îÎ°† Î£®ÌîÑ
# with Íµ¨Î¨∏ÏùÄ ÌååÏù¥Ïç¨Ïùò context manager Î¨∏Î≤ïÏúºÎ°ú, ÏûêÏõê(Î©îÎ™®Î¶¨ Îì±)ÏùÑ ÏûêÎèôÏúºÎ°ú Ïó¥Í≥† Îã´ÏïÑÏ£ºÎäî Ïó≠Ìï†.
# mp_pose.PoseÎ•º ÌÜµÌï¥ MidiapipeÏùò PoseÎ™®Îìà Î∂àÎü¨Ïò¥.
# ÎπÑÎîîÏò§ Ïä§Ìä∏Î¶º(=Ïó∞ÏÜç ÌîÑÎ†àÏûÑ) ÏùÑ Ï≤òÎ¶¨Ìï† ÎïåÎäî FalseÎ°ú Ìï¥Ïïº Îπ†Î¶Ñ.
# ÏÇ¨ÎûåÏùÑ Í≤ÄÏ∂úÌï† ÏµúÏÜå Ïã†Î¢∞ÎèÑ. 0.5Î≥¥Îã§ ÎÇÆÏúºÎ©¥ Ï∂îÎ°† Ïïà Ìï®
# Î™®Îç∏Ïùò Î≥µÏû°ÎèÑ (0: Îπ†Î¶Ñ, 1: Ï§ëÍ∞Ñ, 2: Ï†ïÌôïÌïòÏßÄÎßå ÎäêÎ¶º) ‚Äì Î≥¥ÌÜµ 1Ïù¥Î©¥ Ï∂©Î∂Ñ
# as poseÎ°ú poseÎùºÎäî Ïù¥Î¶Ñ Î∂ôÏûÑÏûÑ
with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1) as pose:
    # Í∞Å ÌôÄÎìúÎ≥Ñ ÌÑ∞Ïπò ÌîÑÎ†àÏûÑ Ïπ¥Ïö¥ÌÑ∞ Ï¥àÍ∏∞Ìôî. Îã§ 0ÏúºÎ°ú ÎßûÏ∂∞Ï§å.
    touch_counters = {i: 0 for i in range(len(hold_contours))}
    TOUCH_THRESHOLD = 10  # ÏµúÏÜå 10ÌîÑÎ†àÏûÑ Ïó∞ÏÜç Ï†ëÏ¥âÌï¥Ïïº ÏßÑÏßú ÌÑ∞Ïπò -> 0.33333Ï¥à(30ÌîÑÎ†àÏûÑ ÏòÅÏÉÅÏù¥ÎãàÎãà)

    #ÏúÑÏóêÏÑú ÌïúÍ±∞Îûë ÎòëÍ∞ôÏùå. ÏòÅÏÉÅ Ïó¨ÎäîÍ±∞.
    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            break

        #ÌîÑÎ†àÏûÑ Ïä§ÌÇµÌï¥Ï£ºÎäî Í±¥Îç∞ ÏÉÅÏú§Ïì∞Í∞Ä ÏµúÏ†ÅÌôî ÌïúÎã§Í≥† ÎÑ£ÏóàÏùå. Í∑ºÎç∞ MediapipeÎ•º ÏµúÏ†ÅÌôî Ìï¥ÏïºÎêòÎäîÍ±∞ Í∞ôÏùå. ÌîÑÎ†àÏûÑÏùÑ ÎÑòÍ∏∞ÎäîÍ≤å ÏïÑÎãàÎùº.
        for _ in range(skip_frames):
            cap.read()

        #ÌôîÎ©¥ ÌöåÏ†Ñ ÏóÜÏñ¥ÎèÑ ÎêòÎäîÍ≤å ÏûàÏùå
        frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
        
        # ÏòÅÏÉÅ Ï†ÄÏû•ÌïòÍ∏∞ ÏúÑÌï¥ÏÑú Ï¥àÍ∏∞ ÏÑ§Ï†ïÏ†ï
        if out is None:
            height, width = frame.shape[:2]
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter('outputs/ex4.mp4', fourcc, fps // (skip_frames + 1), (width, height))

        # ÏãúÍ∞ÅÌôî Ìï† ÌîÑÎ†àÏûÑ Î≥µÏÇ¨Î≥∏. ÏõêÎ≥∏Ïóê ÌïòÎ©¥ ÏõêÎ≥∏ ÌõºÏÜêÎê†Í±∞ÏûñÏïÑ.
        # .copy()Îäî NumpyÏóêÏÑú Ï†úÍ≥µÌïòÎäî Method
        vis_frame = frame.copy()

        def invert_color(bgr):
            return (255 - bgr[0], 255 - bgr[1], 255 - bgr[2])

        for hold in hold_contours:
            cv2.drawContours(vis_frame, [hold["contour"]], -1, hold["color"], 2)
            x, y, w, h = cv2.boundingRect(hold["contour"])
            cv2.putText(vis_frame, hold["label"], (x, y - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, hold["color"], 2, cv2.LINE_AA)
            
            #Ï§ëÏã¨Ï†ê Í∑∏Î¶¨Í∏∞
            cx, cy = hold["center"]
            inverted = invert_color(hold["color"])
            cv2.circle(vis_frame, (cx, cy), 4, inverted, -1)
            cv2.putText(vis_frame, f"({cx}, {cy})", (cx + 6, cy - 6),
                cv2.FONT_HERSHEY_SIMPLEX, 0.4, inverted, 1, cv2.LINE_AA)

        # Mediapipe pose Ï∂îÎ°†
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        result = pose.process(image_rgb)

        important_landmarks = {
            "left_index": 15,
            "right_index": 16,
        }

        hand_parts = {"left_index", "right_index"}

        if result.pose_landmarks:
            h, w = frame.shape[:2]
            coords = {}

            for name, idx in important_landmarks.items():
                landmark = result.pose_landmarks.landmark[idx]
                coords[name] = (landmark.x * w, landmark.y * h)

            csv_writer.writerow([
                frame_idx,
                coords["left_index"][0], coords["left_index"][1],
                coords["right_index"][0], coords["right_index"][1],
            ])
            
            for name, (x, y) in coords.items():
                if name in hand_parts:
                    joint_color = (0, 0, 255)  # ÏÜê: Îπ®Í∞ÑÏÉâ
                cv2.circle(vis_frame, (int(x), int(y)), 5, joint_color, -1)  # Ïõê Í∑∏Î¶¨Í∏∞
                cv2.putText(vis_frame, f"{name}: ({int(x)}, {int(y)})", (int(x)+5, int(y)-5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1, cv2.LINE_AA)

            
            # ÌòÑÏû¨ ÌîÑÎ†àÏûÑÏóêÏÑú Ï†ëÏ¥âÎêú ÌôÄÎìú Ïù∏Îç±Ïä§ Ï†ÄÏû•
            current_touched = set()

            for name, (x, y) in coords.items():
                for i, hold in enumerate(hold_contours):
                    if cv2.pointPolygonTest(hold["contour"], (x, y), False) >= 0:
                        current_touched.add(i)

            # ÌÑ∞Ïπò Ïπ¥Ïö¥Ìä∏ Í∞±Ïã† + ÏÉâÏπ† Ïó¨Î∂Ä ÌåêÎã®
            for name, (x, y) in coords.items():
                for i, hold in enumerate(hold_contours):
                    if cv2.pointPolygonTest(hold["contour"], (x, y), False) >= 0:
                        key = (name, i)
                        touch_counters[key] = touch_counters.get(key, 0) + 1

                        if touch_counters[key] >= TOUCH_THRESHOLD:
                            # ÏÉâÏπ†
                            cv2.drawContours(vis_frame, [hold["contour"]], -1, hold["color"], thickness=cv2.FILLED)

                            # grip Í∏∞Î°ù
                        if already_grabbed.get(key) is None:
                            cx, cy = hold["center"]
                            grip_records.append([name, i, cx, cy])
                            already_grabbed[key] = True
                    else:
                        touch_counters[(name, i)] = 0



        cv2.putText(vis_frame, f"Frame {frame_idx}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)

        # ‚ñ∂Ô∏è ÏµúÏ¢Ö ÏòÅÏÉÅ Î¶¨ÏÇ¨Ïù¥Ï¶à ÌõÑ Ï∂úÎ†•
        vh, vw = vis_frame.shape[:2]
        scale = 400 / vw
        resized = cv2.resize(vis_frame, (int(vw * scale), int(vh * scale)))

        cv2.imshow("YOLO + Pose Landmarks", resized)
        out.write(vis_frame)
        frame_idx += 1

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

cap.release()
csv_file.close()
out.release()
cv2.destroyAllWindows()

with open("data/grip_records.csv", "w", newline='') as f:
    writer = csv.writer(f)
    writer.writerow(["part", "hold_id", "cx", "cy"])
    writer.writerows(grip_records)

# Ï∂úÎ†• ÏòÅÏÉÅ
out = cv2.VideoWriter('outputs/ex4.mp4', ...)
